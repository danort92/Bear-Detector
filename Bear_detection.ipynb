{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danort92/Bear-Detection/blob/main/Bear_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjbccfOVrTA3"
      },
      "source": [
        "#BEAR DETECTOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8xwkNEDrJfy"
      },
      "source": [
        "##LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHaSyBikLRZj"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow keras opencv-python\n",
        "!pip install tensorflow-addons\n",
        "!pip install --upgrade typeguard\n",
        "!pip install ultralytics==8.0.196\n",
        "!pip install roboflow\n",
        "!pip install pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "13o5hRVcUdKl"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import torch\n",
        "import random\n",
        "import shutil\n",
        "import logging\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import yaml\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.metrics import Recall\n",
        "from roboflow import Roboflow\n",
        "from ultralytics import YOLO\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras import backend as K\n",
        "from google.colab import files\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-duSIrFvt1t"
      },
      "source": [
        "##DATASET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTiZflp1yn1Q"
      },
      "source": [
        "###DATASET IMPORT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKRDTjCXLT-N"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/danort92/Bear-Detection.git\n",
        "%cd Bear-Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgGQCmjKyPnn"
      },
      "source": [
        "###DATASET AUGMENTATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VdhCWXS8KOeA"
      },
      "outputs": [],
      "source": [
        "# Define paths based on the directory structure\n",
        "bear_path = 'ct/bear_ct'\n",
        "other_path = 'ct/other_ct'\n",
        "train_dir = 'train'\n",
        "val_dir = 'val'\n",
        "\n",
        "# Create directories for training and validation\n",
        "os.makedirs(os.path.join(train_dir, 'bear'), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, 'other'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'bear'), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, 'other'), exist_ok=True)\n",
        "\n",
        "# Get file paths\n",
        "bear_files = [os.path.join(bear_path, f) for f in os.listdir(bear_path) if os.path.isfile(os.path.join(bear_path, f))]\n",
        "other_files = [os.path.join(other_path, f) for f in os.listdir(other_path) if os.path.isfile(os.path.join(other_path, f))]\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_bear, val_bear = train_test_split(bear_files, test_size=0.2, random_state=42)\n",
        "train_other, val_other = train_test_split(other_files, test_size=0.2, random_state=42)\n",
        "\n",
        "# Copy files to respective directories\n",
        "for f in train_bear:\n",
        "    shutil.copy(f, os.path.join(train_dir, 'bear'))\n",
        "for f in train_other:\n",
        "    shutil.copy(f, os.path.join(train_dir, 'other'))\n",
        "for f in val_bear:\n",
        "    shutil.copy(f, os.path.join(val_dir, 'bear'))\n",
        "for f in val_other:\n",
        "    shutil.copy(f, os.path.join(val_dir, 'other'))\n",
        "\n",
        "# Define paths to training and validation directories\n",
        "train_dir = 'train'\n",
        "val_dir = 'val'\n",
        "\n",
        "# Data generators\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BN1UqhEyAqP"
      },
      "source": [
        "###PLOT DATASET IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tKmtmviamWk"
      },
      "outputs": [],
      "source": [
        "def plot_images_with_labels(generator, num_images=20):\n",
        "    \"\"\"\n",
        "    Plot images from a data generator with their true labels.\n",
        "\n",
        "    Args:\n",
        "        generator: Data generator to provide images and labels.\n",
        "        num_images: Number of images to plot.\n",
        "    \"\"\"\n",
        "    # Get all images and labels from the generator\n",
        "    #generator.reset()  # Ensure we start from the beginning of the generator\n",
        "    images, labels = next(generator)  # Get the first batch\n",
        "    all_images = images\n",
        "    all_labels = labels\n",
        "\n",
        "    # Collect all images and labels\n",
        "    for _ in range(len(generator) - 1):\n",
        "        images, labels = next(generator)\n",
        "        all_images = np.concatenate([all_images, images])\n",
        "        all_labels = np.concatenate([all_labels, labels])\n",
        "\n",
        "    # Randomly sample indices\n",
        "    num_samples = len(all_images)\n",
        "    random_indices = np.random.choice(num_samples, num_images, replace=False)\n",
        "\n",
        "    # Map labels to class names\n",
        "    class_labels = {v: k for k, v in generator.class_indices.items()}\n",
        "\n",
        "    # Plot a subset of images\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, idx in enumerate(random_indices):\n",
        "        img = all_images[idx]\n",
        "        label = all_labels[idx]\n",
        "        label_index = int(label)\n",
        "        true_label = class_labels[label_index]\n",
        "\n",
        "        plt.subplot(4, 5, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'True: {true_label}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"Training images:\")\n",
        "plot_images_with_labels(train_generator, num_images=20)\n",
        "\n",
        "print(\"Validation images:\")\n",
        "plot_images_with_labels(val_generator, num_images=20)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HFjoSUbxv_H"
      },
      "source": [
        "##BEAR - NO BEAR CLASSIFICATION MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnhl7qXPy-sy"
      },
      "source": [
        "###TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAmr1XBTRHvt"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_generator.classes),\n",
        "    y=train_generator.classes\n",
        ")\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "# Load pre-trained model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', Recall()])\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',    # Monitor validation accuracy\n",
        "    patience=2,\n",
        "    restore_best_weights=True  # Restore the best weights\n",
        ")\n",
        "\n",
        "# Train the model with early stopping\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=3,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[early_stopping],\n",
        "    class_weight=class_weights\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcRaYLh7zCOb"
      },
      "source": [
        "###PLOT MODEL PREDICTIONS TO SEE ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79ayhnWOoOjx"
      },
      "outputs": [],
      "source": [
        "THRESHOLD = 0.3\n",
        "\n",
        "def plot_random_predictions(model, generator, num_images=20):\n",
        "    \"\"\"\n",
        "    Plot random images from the validation set with their true and predicted labels.\n",
        "\n",
        "    Args:\n",
        "        model: Trained Keras model.\n",
        "        generator: Data generator to provide images and labels.\n",
        "        num_images: Number of random images to plot.\n",
        "    \"\"\"\n",
        "    # Get all images and labels from the generator\n",
        "    #generator.reset()  # Ensure we start from the beginning of the generator\n",
        "    images, true_labels = next(generator)  # Get the first batch\n",
        "    all_images = images\n",
        "    all_true_labels = true_labels\n",
        "\n",
        "    # Collect all images and labels\n",
        "    for _ in range(len(generator) - 1):\n",
        "        images, true_labels = next(generator)\n",
        "        all_images = np.concatenate([all_images, images])\n",
        "        all_true_labels = np.concatenate([all_true_labels, true_labels])\n",
        "\n",
        "    # Predict labels\n",
        "    predictions = model.predict(all_images)\n",
        "    predicted_labels = (predictions > THRESHOLD).astype(int)\n",
        "\n",
        "    # Map labels to class names\n",
        "    class_labels = {v: k for k, v in generator.class_indices.items()}\n",
        "\n",
        "    # Randomly sample indices\n",
        "    num_samples = len(all_images)\n",
        "    random_indices = np.random.choice(num_samples, num_images, replace=False)\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for i, idx in enumerate(random_indices):\n",
        "        img = all_images[idx]\n",
        "        true_label = class_labels[int(all_true_labels[idx])]\n",
        "        predicted_label = class_labels[int(predicted_labels[idx])]\n",
        "\n",
        "        plt.subplot(4, 5, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'True: {true_label}\\nPredicted: {predicted_label}')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot random images with true and predicted labels\n",
        "plot_random_predictions(model, val_generator, num_images=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry4NSRrxzKZa"
      },
      "source": [
        "###PLOT MODEL METRICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnF2cg2YuMrw"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    Plot training and validation accuracy and loss.\n",
        "\n",
        "    Args:\n",
        "        history: Training history object returned by model.fit().\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot recall\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(history.history['recall'], label='Train Recall')\n",
        "    plt.plot(history.history['val_recall'], label='Validation Recall')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Recall')\n",
        "    plt.title('Model Recall')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot training history\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S73ZTAugvRZI"
      },
      "outputs": [],
      "source": [
        "def evaluate_with_threshold(model, generator, threshold=THRESHOLD):\n",
        "    \"\"\"\n",
        "    Evaluate the model using a custom threshold and compute metrics.\n",
        "\n",
        "    Args:\n",
        "        model: Trained Keras model.\n",
        "        generator: Data generator to provide images and labels.\n",
        "        threshold: Classification threshold.\n",
        "    \"\"\"\n",
        "    # Predict labels for the entire validation set\n",
        "    all_predictions = []\n",
        "    all_true_labels = []\n",
        "\n",
        "    # Ensure generator starts from the beginning\n",
        "    #generator.reset()\n",
        "\n",
        "    # Iterate over the generator to get all images and labels\n",
        "    for _ in range(len(generator)):\n",
        "        images, true_labels = next(generator)\n",
        "        predictions = model.predict(images)\n",
        "        all_predictions.extend(predictions.flatten())\n",
        "        all_true_labels.extend(true_labels.flatten())\n",
        "\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_true_labels = np.array(all_true_labels)\n",
        "\n",
        "    # Apply threshold to predictions\n",
        "    predicted_labels = (all_predictions > threshold).astype(int)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(all_true_labels, predicted_labels)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Other', 'Bear'])\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "    plt.title(f'Confusion Matrix (Threshold = {threshold})')\n",
        "    plt.show()\n",
        "\n",
        "    # Print classification report\n",
        "    report = classification_report(all_true_labels, predicted_labels, target_names=['Other', 'Bear'])\n",
        "    print(f\"\\n Classification Report (Threshold = {threshold}):\\n{report}\")\n",
        "\n",
        "    return predicted_labels, all_true_labels\n",
        "\n",
        "predicted_labels, true_labels = evaluate_with_threshold(model, val_generator, threshold=THRESHOLD)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_predict(model, threshold=THRESHOLD):\n",
        "    \"\"\"\n",
        "    Function to upload and predict on images using the trained model.\n",
        "    Allows the user to upload either a single image or a zip file.\n",
        "    Saves predicted Bear and Other images into separate timestamped folders.\n",
        "\n",
        "    Args:\n",
        "        model: Trained Keras model.\n",
        "        threshold: Classification threshold.\n",
        "    \"\"\"\n",
        "    # Create a predictions directory with a timestamp\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    base_dir = f\"predictions/{timestamp}\"\n",
        "    bear_dir = os.path.join(base_dir, \"predicted_bears\")\n",
        "    other_dir = os.path.join(base_dir, \"predicted_others\")\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(bear_dir, exist_ok=True)\n",
        "    os.makedirs(other_dir, exist_ok=True)\n",
        "\n",
        "    upload_choice = input(\"Do you want to upload a new image or zip file? (yes/no): \").lower()\n",
        "\n",
        "    if upload_choice in ['yes', 'y']:\n",
        "        file_choice = input(\"Do you want to upload a zip file? (yes/no): \").lower()\n",
        "\n",
        "        if file_choice in ['yes', 'y']:\n",
        "            print(\"Please upload a zip file containing your images.\")\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            uploaded_dir = \"uploaded_images\"\n",
        "            if os.path.exists(uploaded_dir):\n",
        "                shutil.rmtree(uploaded_dir)\n",
        "            os.makedirs(uploaded_dir)\n",
        "\n",
        "            for filename in uploaded.keys():\n",
        "                if filename.endswith('.zip'):\n",
        "                    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "                        zip_ref.extractall(uploaded_dir)\n",
        "                    print(f\"Extracted files to '{uploaded_dir}' directory.\")\n",
        "\n",
        "            uploaded_images = [os.path.join(uploaded_dir, f) for f in os.listdir(uploaded_dir) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
        "\n",
        "            bear_count = 0\n",
        "            other_count = 0\n",
        "\n",
        "            for image_path in uploaded_images:\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    print(f\"Error loading image: {image_path}\")\n",
        "                    continue\n",
        "\n",
        "                image_resized = cv2.resize(image, (224, 224))\n",
        "                image_rescaled = image_resized / 255.0\n",
        "                image_batch = np.expand_dims(image_rescaled, axis=0)\n",
        "\n",
        "                print(f\"Image Shape: {image_batch.shape}\")\n",
        "                print(f\"Image Max Value: {np.max(image_batch)}, Min Value: {np.min(image_batch)}\")\n",
        "\n",
        "                prediction = model.predict(image_batch)\n",
        "                print(f\"Prediction Array: {prediction}\")\n",
        "\n",
        "                label = 'Bear' if prediction < (1-threshold) else 'Other'\n",
        "                print(f\"Image: {os.path.basename(image_path)}, Label: {label}\")\n",
        "\n",
        "                # Save the image in the appropriate folder\n",
        "                if label == 'Bear':\n",
        "                    bear_count += 1\n",
        "                    save_path = os.path.join(bear_dir, os.path.basename(image_path))\n",
        "                else:\n",
        "                    other_count += 1\n",
        "                    save_path = os.path.join(other_dir, os.path.basename(image_path))\n",
        "\n",
        "                cv2.imwrite(save_path, image)  # Save the image in the corresponding directory\n",
        "\n",
        "            print(f\"\\nSummary:\\nTotal Images: {len(uploaded_images)}\\nBear Images: {bear_count}\\nOther Images: {other_count}\")\n",
        "\n",
        "        else:\n",
        "            print(\"Please upload an image file.\")\n",
        "            uploaded = files.upload()\n",
        "\n",
        "            for filename in uploaded.keys():\n",
        "                image_path = filename\n",
        "\n",
        "                image = cv2.imread(image_path)\n",
        "                if image is None:\n",
        "                    print(f\"Error loading image: {image_path}\")\n",
        "                    continue\n",
        "\n",
        "                image_resized = cv2.resize(image, (224, 224))\n",
        "                image_rescaled = image_resized / 255.0\n",
        "                image_batch = np.expand_dims(image_rescaled, axis=0)\n",
        "\n",
        "                print(f\"Image Shape: {image_batch.shape}\")\n",
        "                print(f\"Image Max Value: {np.max(image_batch)}, Min Value: {np.min(image_batch)}\")\n",
        "\n",
        "                prediction = model.predict(image_batch)\n",
        "                print(f\"Prediction Array: {prediction}\")\n",
        "\n",
        "                label = 'Bear' if prediction < (1-threshold) else 'Other'\n",
        "                print(f\"Image: {image_path}, Label: {label}\")\n",
        "\n",
        "                # Save the image in the appropriate folder\n",
        "                if label == 'Bear':\n",
        "                    save_path = os.path.join(bear_dir, os.path.basename(image_path))\n",
        "                else:\n",
        "                    save_path = os.path.join(other_dir, os.path.basename(image_path))\n",
        "\n",
        "                cv2.imwrite(save_path, image)  # Save the image in the corresponding directory\n",
        "\n",
        "    else:\n",
        "        print(\"No images uploaded.\")"
      ],
      "metadata": {
        "id": "UwuirLgAQiBP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upload_and_predict(model, threshold=THRESHOLD)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "90ezPDRLzVDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWCIkBx7zTvU"
      },
      "source": [
        "###NOTES\n",
        "The model effectively recognizes if bears are present or not in the camera trap images and saves uploaded user's pics in Predictions folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhf5JYaazSrD"
      },
      "source": [
        "## BEAR DETECTION MODEL\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxUlXkS608CT"
      },
      "source": [
        "###TRAIN YOLOv8 MODEL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the data.yaml file in a given directory\n",
        "def find_yaml_file(directory, filename=\"data.yaml\"):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        if filename in files:\n",
        "            return os.path.join(root, filename)\n",
        "    return None\n",
        "\n",
        "# Function to find the train and validation folders automatically\n",
        "def find_data_folders(base_dir):\n",
        "    train_dir = None\n",
        "    val_dir = None\n",
        "\n",
        "    for dirpath, dirnames, filenames in os.walk(base_dir):\n",
        "        if \"train\" in dirpath and \"images\" in dirpath:\n",
        "            train_dir = dirpath\n",
        "        elif \"test\" in dirpath and \"images\" in dirpath:\n",
        "            val_dir = dirpath\n",
        "\n",
        "    return train_dir, val_dir\n",
        "\n",
        "def setup_bear_detection(api_key, workspace_name, project_name, version_number):\n",
        "    rf = Roboflow(api_key=api_key)\n",
        "    project = rf.workspace(workspace_name).project(project_name)\n",
        "    version = project.version(version_number)\n",
        "    dataset = version.download(\"yolov8\")\n",
        "\n",
        "    base_dir = f\"/content/Bear-Detection/Bear-detection-{version_number}/\"\n",
        "    yaml_file_path = find_yaml_file(base_dir)\n",
        "    train_path, val_path = find_data_folders(base_dir)\n",
        "\n",
        "    if yaml_file_path and train_path and val_path:\n",
        "        with open(yaml_file_path, 'r') as file:\n",
        "            data = yaml.safe_load(file)\n",
        "        data['train'] = train_path\n",
        "        data['val'] = val_path\n",
        "\n",
        "        with open(yaml_file_path, 'w') as file:\n",
        "            yaml.safe_dump(data, file)\n",
        "\n",
        "        return yaml_file_path, version_number\n",
        "\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Required files or directories not found.\")\n",
        "\n",
        "def setup_bear_detection_from_local(base_dir):\n",
        "    yaml_file_path = find_yaml_file(base_dir)\n",
        "    train_path, val_path = find_data_folders(base_dir)\n",
        "\n",
        "    if yaml_file_path and train_path and val_path:\n",
        "        with open(yaml_file_path, 'r') as file:\n",
        "            data = yaml.safe_load(file)\n",
        "        data['train'] = train_path\n",
        "        data['val'] = val_path\n",
        "\n",
        "        with open(yaml_file_path, 'w') as file:\n",
        "            yaml.safe_dump(data, file)\n",
        "\n",
        "        return yaml_file_path\n",
        "\n",
        "# Function to handle zip file upload and extraction\n",
        "def handle_zip_upload(zip_file_path):\n",
        "    # Extract the zip file\n",
        "    extract_path = '/content/Bear-Detection/zip_extracted'\n",
        "    os.makedirs(extract_path, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    return extract_path\n",
        "\n",
        "# Step 1: Ask the user if they want to use pre-trained weights\n",
        "use_pretrained_weights = input(\"Do you want to use pre-trained weights? (yes/no): \").lower()\n",
        "\n",
        "if use_pretrained_weights in ['yes', 'y']:\n",
        "    print(\"Please upload the pre-trained weights file (or a zip containing the weights).\")\n",
        "    uploaded = files.upload()\n",
        "    uploaded_file = list(uploaded.keys())[0]\n",
        "\n",
        "    if uploaded_file.endswith('.zip'):\n",
        "        extract_path = handle_zip_upload(uploaded_file)\n",
        "        weights_path = os.path.join(extract_path, \"best.pt\")  # Adjust as needed based on the zip file contents\n",
        "    else:\n",
        "        weights_path = uploaded_file\n",
        "\n",
        "    loaded_model = YOLO(weights_path)\n",
        "    print(\"Pre-trained weights loaded successfully. Skipping training.\")\n",
        "else:\n",
        "    # Step 2: Ask the user if they want to use the locally available dataset or their own Roboflow dataset\n",
        "    dataset_choice = input(\"Do you want to use the pre-labeled dataset from your local files? (yes/no): \").lower()\n",
        "\n",
        "    if dataset_choice in ['yes', 'y']:\n",
        "        base_dir = \"/content/Bear-Detection/Bear detection.v3i.yolov8-obb\"  # Adjust this path if needed\n",
        "        data_yaml_path = setup_bear_detection_from_local(base_dir)\n",
        "    else:\n",
        "        api_key = input(\"Enter your Roboflow API key: \")\n",
        "        workspace_name = input(\"Enter your Roboflow workspace name: \")\n",
        "        project_name = input(\"Enter your Roboflow project name: \")\n",
        "        version_number = int(input(\"Enter the version number of the dataset: \"))\n",
        "        data_yaml_path, version_number = setup_bear_detection(api_key, workspace_name, project_name, version_number)\n",
        "\n",
        "    # Load YOLOv8 model and train the model if no pre-saved weights are used\n",
        "    loaded_model = YOLO(\"yolov8n.pt\")\n",
        "    loaded_model.train(\n",
        "        data=data_yaml_path,\n",
        "        epochs=1,\n",
        "        imgsz=416,\n",
        "        batch=16,\n",
        "        optimizer=\"AdamW\",\n",
        "        lr0=0.001,\n",
        "        weight_decay=0.0005,\n",
        "        augment=False,\n",
        "        half=True  # Enable mixed precision for faster computation\n",
        "    )\n",
        "\n",
        "    # After training, ask the user if they want to save the trained weights\n",
        "    save_weights = input(\"Do you want to save the trained weights? (yes/no): \").lower()\n",
        "\n",
        "    if save_weights in ['yes', 'y']:\n",
        "        model_dir = \"/content/Bear-Detection/runs/detect/train/weights\"\n",
        "        zip_file_path = \"/content/exported_model.zip\"\n",
        "        shutil.make_archive(\"/content/exported_model\", 'zip', model_dir)\n",
        "\n",
        "        print(\"Zipped model files:\", os.listdir(\"/content/\"))\n",
        "\n",
        "        # Download the zipped model file\n",
        "        files.download(zip_file_path)\n",
        "\n",
        "# Print confirmation\n",
        "print(\"Process completed successfully!\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AxGqwjAn8cEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpL3PV3p5ymg",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Function to process video with YOLO\n",
        "def process_video_with_yolo(video_path, model, output_path=None):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error opening video file: {video_path}\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # Create a VideoWriter object if output_path is provided\n",
        "    if output_path:\n",
        "        out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
        "\n",
        "    # Suppress output from the model prediction\n",
        "    logging.getLogger('ultralytics').setLevel(logging.ERROR)\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = model.predict(frame_rgb, verbose=False)  # Suppress verbose output\n",
        "\n",
        "        # Draw bounding boxes\n",
        "        for bbox in results[0].boxes.xyxy:\n",
        "            x1, y1, x2, y2 = map(int, bbox)\n",
        "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "            cv2.putText(frame, 'Predicted BB', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "        # Write the frame to the output video if output_path is provided\n",
        "        if output_path:\n",
        "            out.write(frame)\n",
        "\n",
        "    cap.release()\n",
        "    if output_path:\n",
        "        out.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def setup_and_process_videos():\n",
        "    # Directories\n",
        "    video_files_dir = '/content/Bear-Detection/video_files'\n",
        "    processed_videos_dir = '/content/Bear-Detection/processed_videos'\n",
        "\n",
        "    # Create directories if they do not exist\n",
        "    os.makedirs(video_files_dir, exist_ok=True)\n",
        "    os.makedirs(processed_videos_dir, exist_ok=True)\n",
        "\n",
        "    # Upload video files\n",
        "    print(\"Upload video files:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # List uploaded files\n",
        "    video_files = list(uploaded.keys())\n",
        "    print(\"Uploaded video files:\", video_files)\n",
        "\n",
        "    # Save uploaded files to video_files_dir\n",
        "    for video_file in video_files:\n",
        "        file_path = os.path.join(video_files_dir, video_file)\n",
        "        with open(file_path, 'wb') as f:\n",
        "            f.write(uploaded[video_file])\n",
        "        print(f\"Uploaded and saved {video_file} to {video_files_dir}\")\n",
        "\n",
        "    # Automatically find all .mp4 files in the video_files_dir\n",
        "    video_files = [os.path.join(video_files_dir, f) for f in os.listdir(video_files_dir) if f.endswith('.mp4')]\n",
        "\n",
        "    # Load your model here\n",
        "    model = YOLO(\"yolov8n.pt\")  # Adjust model as needed\n",
        "\n",
        "    # Process each video file and save the output\n",
        "    for video_file in video_files:\n",
        "        output_file = os.path.join(processed_videos_dir, os.path.basename(video_file).replace('.mp4', '_processed.mp4'))\n",
        "        print(f\"Processing video: {video_file}\")\n",
        "        process_video_with_yolo(video_file, model, output_file)\n",
        "        print(f\"Processed video saved as: {output_file}\")\n",
        "\n",
        "    # Print the directory where the processed videos are saved\n",
        "    print(f\"\\nAll processed videos are saved in: {processed_videos_dir}\")\n",
        "\n",
        "# Run the setup and processing function\n",
        "setup_and_process_videos()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srOpZSS61MR_"
      },
      "source": [
        "### NOTES\n",
        "\n",
        "This project provides a comprehensive setup for bear detection using YOLOv8. It offers flexibility in using pre-trained models or training from scratch with local or cloud datasets. The video processing functionality further extends the projectâ€™s capabilities, allowing for real-time bear detection in video footage. This tool can be valuable for wildlife monitoring and research, offering an efficient method to identify and track bears in various environments.\n",
        "\n",
        "It still improvable using a bigger camera traps set and adding more standing up bear images. Due to its flexibility the model can be easily adaptable to track animals different from bears with small code apatations.\n",
        "\n",
        "Future developments, with enough available data: single bear detection (work in progress...)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOve0hbrKm9GWNy59vI8WZr",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}