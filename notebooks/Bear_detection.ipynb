{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ðŸ» Bear Detector\n\n**Binary image classification** (MobileNetV2) + **object detection in video** (YOLOv8)  \nfor wildlife camera-trap footage.\n\n> Run in **Google Colab** (GPU recommended) or a local environment.  \n> All configurable parameters live in the first code cell.\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 0 Â· Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, sys\nfrom pathlib import Path\n\n# â”€â”€ Colab: clone repo and cd into it â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nIN_COLAB = \"google.colab\" in sys.modules\nif IN_COLAB:\n    !git clone --quiet https://github.com/danort92/Bear-Detector.git\n    os.chdir(\"Bear-Detector\")\n\n# â”€â”€ Local: make sure we are at the repo root â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nREPO_ROOT = Path.cwd()\n# Add src/ to the Python path so bear_detector is importable\nif str(REPO_ROOT / \"src\") not in sys.path:\n    sys.path.insert(0, str(REPO_ROOT / \"src\"))\n\nprint(\"Working directory:\", REPO_ROOT)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1 Â· Install Dependencies"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install once; comment out if dependencies are already installed.\n%pip install -q -r requirements.txt\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2 Â· Configuration\n\nAll hyperparameters and paths are centralised here."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from bear_detector.config import ClassificationConfig, DetectionConfig\n\nclf_cfg = ClassificationConfig(\n    bear_dir=\"ct/bear_ct\",\n    other_dir=\"ct/other_ct\",\n    epochs=20,\n    learning_rate=1e-4,\n    threshold=0.3,        # P(bear) >= threshold  â†’  \"Bear\"\n)\n\ndet_cfg = DetectionConfig(\n    epochs=50,\n    image_size=640,\n    batch_size=16,\n)\n\nprint(\"Classification config:\", clf_cfg)\nprint(\"Detection config:\", det_cfg)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3 Â· Imports"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, shutil, zipfile\nfrom datetime import datetime\nfrom pathlib import Path\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport yaml\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\nfrom sklearn.utils import class_weight\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.metrics import Recall\n\nfrom bear_detector.utils import load_and_preprocess, batch_from_path, collect_images_from_dir, extract_zip\nfrom bear_detector.classification import prepare_split_dirs, build_model, train_classification_model, predict_image\nfrom bear_detector.detection import setup_local_dataset, setup_roboflow_dataset, train_detection_model, process_video\n\n# Optional: Colab-specific display helpers\ntry:\n    from google.colab.patches import cv2_imshow\n    from google.colab import files as colab_files\n    IN_COLAB = True\nexcept ImportError:\n    IN_COLAB = False\n    print(\"Not running in Colab â€” file upload/download cells will be skipped.\")\n\nprint(\"TensorFlow:\", tf.__version__)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4 Â· Classification Dataset\n\n### 4.1 Train/Val Split"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "n_train_bear, n_val_bear, n_train_other, n_val_other = prepare_split_dirs(\n    bear_dir=clf_cfg.bear_dir,\n    other_dir=clf_cfg.other_dir,\n    train_dir=clf_cfg.train_dir,\n    val_dir=clf_cfg.val_dir,\n    val_split=clf_cfg.val_split,\n    random_seed=clf_cfg.random_seed,\n)\n\nprint(f\"Training   â€” bear: {n_train_bear:4d} | other: {n_train_other:4d}\")\nprint(f\"Validation â€” bear: {n_val_bear:4d} | other: {n_val_other:4d}\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.2 Data Generators"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "train_datagen = ImageDataGenerator(\n    rescale=1.0 / 255,\n    rotation_range=clf_cfg.rotation_range,\n    width_shift_range=clf_cfg.width_shift_range,\n    height_shift_range=clf_cfg.height_shift_range,\n    shear_range=clf_cfg.shear_range,\n    zoom_range=clf_cfg.zoom_range,\n    horizontal_flip=clf_cfg.horizontal_flip,\n)\nval_datagen = ImageDataGenerator(rescale=1.0 / 255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    clf_cfg.train_dir,\n    target_size=clf_cfg.image_size,\n    batch_size=clf_cfg.batch_size,\n    class_mode=\"binary\",\n)\nval_generator = val_datagen.flow_from_directory(\n    clf_cfg.val_dir,\n    target_size=clf_cfg.image_size,\n    batch_size=clf_cfg.batch_size,\n    class_mode=\"binary\",\n    shuffle=False,\n)\n\nprint(\"Class indices:\", train_generator.class_indices)\n# Expected: {'bear': 0, 'other': 1}\n# Model output = P(other); P(bear) = 1 - output\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4.3 Visualise Dataset Samples"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_generator_samples(\n    generator: ImageDataGenerator,\n    num_images: int = 20,\n    title: str = \"\",\n) -> None:\n    \"\"\"Plot a random sample of images from a Keras image generator.\n\n    Args:\n        generator: A ``DirectoryIterator`` (from ``flow_from_directory``).\n        num_images: How many images to display.\n        title: Optional figure title.\n    \"\"\"\n    generator.reset()\n    class_labels = {v: k for k, v in generator.class_indices.items()}\n\n    all_images: list[np.ndarray] = []\n    all_labels: list[float] = []\n    for _ in range(len(generator)):\n        imgs, lbls = next(generator)\n        all_images.append(imgs)\n        all_labels.append(lbls)\n\n    all_images_arr = np.concatenate(all_images, axis=0)\n    all_labels_arr = np.concatenate(all_labels, axis=0)\n\n    num_images = min(num_images, len(all_images_arr))\n    indices = np.random.choice(len(all_images_arr), num_images, replace=False)\n\n    cols = 5\n    rows = (num_images + cols - 1) // cols\n    plt.figure(figsize=(15, rows * 3))\n    if title:\n        plt.suptitle(title, fontsize=14, y=1.02)\n\n    for plot_idx, img_idx in enumerate(indices):\n        label_name = class_labels[int(all_labels_arr[img_idx])]\n        plt.subplot(rows, cols, plot_idx + 1)\n        plt.imshow(all_images_arr[img_idx])\n        plt.title(label_name, fontsize=9)\n        plt.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n\n\nplot_generator_samples(train_generator, num_images=20, title=\"Training samples\")\nplot_generator_samples(val_generator, num_images=20, title=\"Validation samples\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5 Â· Train Classification Model"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "model, history = train_classification_model(\n    train_dir=clf_cfg.train_dir,\n    val_dir=clf_cfg.val_dir,\n    image_size=clf_cfg.image_size,\n    batch_size=clf_cfg.batch_size,\n    epochs=clf_cfg.epochs,\n    learning_rate=clf_cfg.learning_rate,\n    early_stopping_patience=clf_cfg.early_stopping_patience,\n    dense_units=clf_cfg.dense_units,\n    dropout_rate=clf_cfg.dropout_rate,\n)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6 Â· Evaluate Classification Model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6.1 Training Curves"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_training_history(history: tf.keras.callbacks.History) -> None:\n    \"\"\"Plot accuracy, recall, and loss curves from training history.\n\n    Args:\n        history: Object returned by ``model.fit()``.\n    \"\"\"\n    metrics = [\n        (\"accuracy\", \"Accuracy\"),\n        (\"recall\", \"Recall\"),\n        (\"loss\", \"Loss\"),\n    ]\n    fig, axes = plt.subplots(1, len(metrics), figsize=(5 * len(metrics), 4))\n    for ax, (key, label) in zip(axes, metrics):\n        ax.plot(history.history[key], label=f\"Train {label}\")\n        ax.plot(history.history[f\"val_{key}\"], label=f\"Val {label}\")\n        ax.set_xlabel(\"Epoch\")\n        ax.set_ylabel(label)\n        ax.set_title(label)\n        ax.legend()\n    plt.tight_layout()\n    plt.show()\n\n\nplot_training_history(history)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6.2 Confusion Matrix & Classification Report"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def evaluate_with_threshold(\n    model: tf.keras.Model,\n    generator: ImageDataGenerator,\n    threshold: float = 0.3,\n) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"Collect all predictions and compute classification metrics.\n\n    The model output is ``P(other)``.  A sample is predicted as *Bear* when\n    ``1 - model_output >= threshold``, i.e. ``model_output < 1 - threshold``.\n\n    Args:\n        model: Trained Keras classification model.\n        generator: Validation ``DirectoryIterator`` (``shuffle=False``).\n        threshold: Minimum P(bear) to predict \"Bear\".\n\n    Returns:\n        Tuple of ``(predicted_class_indices, true_class_indices)``.\n    \"\"\"\n    generator.reset()\n    all_preds: list[float] = []\n    all_true: list[float] = []\n\n    for _ in range(len(generator)):\n        images, true_labels = next(generator)\n        preds = model.predict(images, verbose=0)\n        all_preds.extend(preds.flatten().tolist())\n        all_true.extend(true_labels.flatten().tolist())\n\n    all_preds_arr = np.array(all_preds)\n    all_true_arr = np.array(all_true, dtype=int)\n\n    # predicted class: 0 (bear) when P(bear)=1-output >= threshold\n    predicted = (all_preds_arr >= (1.0 - threshold)).astype(int)\n\n    cm = confusion_matrix(all_true_arr, predicted)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Bear\", \"Other\"])\n    disp.plot(cmap=plt.cm.Blues)\n    plt.title(f\"Confusion Matrix  (threshold = {threshold})\")\n    plt.show()\n\n    report = classification_report(all_true_arr, predicted, target_names=[\"Bear\", \"Other\"])\n    print(f\"\\nClassification Report (threshold = {threshold}):\\n{report}\")\n\n    return predicted, all_true_arr\n\n\npredicted_labels, true_labels = evaluate_with_threshold(\n    model, val_generator, threshold=clf_cfg.threshold\n)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6.3 Sample Predictions"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_random_predictions(\n    model: tf.keras.Model,\n    generator: ImageDataGenerator,\n    threshold: float = 0.3,\n    num_images: int = 20,\n) -> None:\n    \"\"\"Display a random grid of validation images with true and predicted labels.\n\n    Args:\n        model: Trained Keras model.\n        generator: Validation ``DirectoryIterator`` (``shuffle=False``).\n        threshold: Minimum P(bear) to predict \"Bear\".\n        num_images: Number of images to display.\n    \"\"\"\n    generator.reset()\n    class_labels = {v: k for k, v in generator.class_indices.items()}\n\n    all_images: list[np.ndarray] = []\n    all_true: list[float] = []\n    for _ in range(len(generator)):\n        imgs, lbls = next(generator)\n        all_images.append(imgs)\n        all_true.append(lbls)\n\n    all_images_arr = np.concatenate(all_images, axis=0)\n    all_true_arr = np.concatenate(all_true, axis=0)\n\n    raw_preds = model.predict(all_images_arr, verbose=0).flatten()\n    # predicted class index: 0 (bear) when P(bear) >= threshold\n    predicted_classes = (raw_preds >= (1.0 - threshold)).astype(int)\n\n    num_images = min(num_images, len(all_images_arr))\n    indices = np.random.choice(len(all_images_arr), num_images, replace=False)\n\n    cols = 5\n    rows = (num_images + cols - 1) // cols\n    plt.figure(figsize=(15, rows * 3))\n    for plot_idx, img_idx in enumerate(indices):\n        true_name = class_labels[int(all_true_arr[img_idx])]\n        pred_name = class_labels[int(predicted_classes[img_idx])]\n        color = \"green\" if true_name == pred_name else \"red\"\n        plt.subplot(rows, cols, plot_idx + 1)\n        plt.imshow(all_images_arr[img_idx])\n        plt.title(f\"True: {true_name}\\nPred: {pred_name}\", fontsize=8, color=color)\n        plt.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n\n\nplot_random_predictions(model, val_generator, threshold=clf_cfg.threshold, num_images=20)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7 Â· Run Inference on New Images\n\n*(Colab only â€” uses `google.colab.files.upload()`)*"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def upload_and_predict(\n    model: tf.keras.Model,\n    threshold: float = 0.3,\n    image_size: tuple[int, int] = (224, 224),\n) -> None:\n    \"\"\"Interactive inference: upload images (or a ZIP), classify, and save results.\n\n    Results are written to ``predictions/<timestamp>/predicted_bears/`` and\n    ``predictions/<timestamp>/predicted_others/``.\n\n    Args:\n        model: Trained Keras classification model.\n        threshold: Minimum P(bear) to label an image as \"Bear\".\n        image_size: *(W, H)* expected by the model.\n    \"\"\"\n    if not IN_COLAB:\n        print(\"This cell requires Google Colab.\")\n        return\n\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    bear_dir = Path(\"predictions\") / timestamp / \"predicted_bears\"\n    other_dir = Path(\"predictions\") / timestamp / \"predicted_others\"\n    bear_dir.mkdir(parents=True, exist_ok=True)\n    other_dir.mkdir(parents=True, exist_ok=True)\n\n    uploaded = colab_files.upload()\n    if not uploaded:\n        print(\"No files uploaded.\")\n        return\n\n    image_paths: list[Path] = []\n    for filename in uploaded:\n        fpath = Path(filename)\n        if filename.endswith(\".zip\"):\n            extracted = extract_zip(fpath, Path(\"uploaded_images\"))\n            image_paths.extend(collect_images_from_dir(extracted))\n        elif fpath.suffix.lower() in {\".jpg\", \".jpeg\", \".png\"}:\n            image_paths.append(fpath)\n        else:\n            print(f\"Skipping unsupported file: {filename}\")\n\n    bear_count = other_count = 0\n    for img_path in image_paths:\n        batch = batch_from_path(img_path, target_size=image_size)\n        if batch is None:\n            print(f\"[WARN] Could not load: {img_path.name}\")\n            continue\n\n        label, bear_prob = predict_image(model, batch, threshold=threshold)\n        dest_dir = bear_dir if label == \"Bear\" else other_dir\n        shutil.copy(img_path, dest_dir / img_path.name)\n\n        if label == \"Bear\":\n            bear_count += 1\n        else:\n            other_count += 1\n\n        print(f\"{img_path.name:40s}  â†’  {label}  (P(bear)={bear_prob:.3f})\")\n\n    total = bear_count + other_count\n    print(f\"\\nDone â€” {total} images | Bear: {bear_count} | Other: {other_count}\")\n    print(f\"Results saved in predictions/{timestamp}/\")\n\n\nupload_and_predict(model, threshold=clf_cfg.threshold, image_size=clf_cfg.image_size)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8 Â· YOLOv8 Bear Detection Model"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 8.1 Dataset Setup"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# â”€â”€ Option A: Use the local Roboflow dataset included in the repo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nLOCAL_DATASET_DIR = \"Bear detection.v3i.yolov8-obb\"\ndata_yaml_path = setup_local_dataset(LOCAL_DATASET_DIR)\nprint(\"data.yaml:\", data_yaml_path)\n\n# â”€â”€ Option B: Download a custom dataset from Roboflow â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# api_key = os.environ.get(\"ROBOFLOW_API_KEY\")   # set via Colab Secrets or .env\n# if api_key is None:\n#     raise EnvironmentError(\"ROBOFLOW_API_KEY not set.\")\n# data_yaml_path = setup_roboflow_dataset(\n#     api_key=api_key,\n#     workspace=\"your-workspace\",\n#     project=\"your-project\",\n#     version=1,\n# )\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 8.2 Train or Load Weights"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "USE_PRETRAINED = False  # Set to True and provide WEIGHTS_PATH to skip training\n\nWEIGHTS_PATH = \"best.pt\"  # Path to your .pt weights file\n\nif USE_PRETRAINED:\n    from ultralytics import YOLO\n    yolo_model = YOLO(WEIGHTS_PATH)\n    print(\"Loaded pre-trained weights from\", WEIGHTS_PATH)\nelse:\n    yolo_model = train_detection_model(\n        data_yaml=data_yaml_path,\n        model_name=det_cfg.model_name,\n        epochs=det_cfg.epochs,\n        image_size=det_cfg.image_size,\n        batch_size=det_cfg.batch_size,\n        optimizer=det_cfg.optimizer,\n        learning_rate=det_cfg.learning_rate,\n        weight_decay=det_cfg.weight_decay,\n        augment=det_cfg.augment,\n        half_precision=det_cfg.half_precision,\n    )\n    print(\"Training complete.\")\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 8.3 Process Video"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_video_inference(yolo_model) -> None:\n    \"\"\"Upload a video (Colab), run YOLOv8 detection, and save the annotated output.\"\"\"\n    if not IN_COLAB:\n        print(\"This cell requires Google Colab.\")\n        return\n\n    video_dir = Path(\"video_files\")\n    output_dir = Path(\"processed_videos\")\n    video_dir.mkdir(exist_ok=True)\n    output_dir.mkdir(exist_ok=True)\n\n    print(\"Upload your video file(s) (.mp4):\")\n    uploaded = colab_files.upload()\n\n    for filename, data in uploaded.items():\n        video_path = video_dir / filename\n        video_path.write_bytes(data)\n\n        output_path = output_dir / filename.replace(\".mp4\", \"_detected.mp4\")\n        print(f\"Processing {filename} â€¦\")\n        n_frames = process_video(video_path, yolo_model, output_path=output_path)\n        print(f\"Done â€” {n_frames} frames  â†’  {output_path}\")\n\n\nrun_video_inference(yolo_model)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9 Â· Save / Export Trained Weights\n\n*(Colab only)*"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "if IN_COLAB:\n    # Classification model (Keras .keras format)\n    model.save(\"bear_classifier.keras\")\n    colab_files.download(\"bear_classifier.keras\")\n\n    # YOLOv8 weights (best.pt lives inside runs/detect/train/weights/)\n    import glob as _glob\n    best_pts = _glob.glob(\"runs/detect/train*/weights/best.pt\")\n    if best_pts:\n        shutil.make_archive(\"yolo_weights\", \"zip\", os.path.dirname(best_pts[0]))\n        colab_files.download(\"yolo_weights.zip\")\n    else:\n        print(\"No YOLOv8 weights found. Make sure training completed.\")\nelse:\n    print(\"Save manually: model.save('bear_classifier.keras')\")\n"
  }
 ]
}